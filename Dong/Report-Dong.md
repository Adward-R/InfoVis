## 报道数量与时间和主要报社关系分析：区域式折线图和堆栈式区域图
### 数据来源
1. articles文件夹中所有的845篇报道，包含时间、报社信息（绝大多数）和正文内容

### 数据预处理
1. 编写python脚本分析所有的报道文本，识别出对应的发文时间和报社信息并转化为统一的格式，存入中间文件`articleTime.csv`以备后续数据预处理过程方便使用
2. 编写python脚本从中间文件中读取数据，将报道按日期切分复制到`ByDay/`中的各个子文件夹，并分别统计各个有报道文章出现的日期的文章数量，以`tsv day-month-year	number`格式存储
3. 编写python脚本从中间文件中读取数据，将报道按年份切分复制到`ByYear/`中的各个子文件夹，并分别统计各年度几个主要报社的文章在它们的文章总数中所占比例，以`year	The-Abila-Post	News-Online-Today	Kronos-Star	Homeland-Illumination	Centrum-Sentinel`格式存储，其中每项数字都是以0-100的浮点数表示的比例值。

### 数据可视化
 - 一个表示总的报道数量随时间推延的变化趋势的区域式折线图，横轴表示日期，纵轴蓝色部分高度表示当日的文章数量；能够清晰地分辨出文章高度集中在14年往后的情况，因此对近期文章进行基于时间序列关系的分析并非十分有效
 - 一个表示几个主要报社（发文总数量占优的五家）每年度报道数量占它们总和比例的堆栈式区域图，每种颜色代表一个报社，同种颜色在同一横轴座标上对应的纵轴高度表示相对的报道数量比例；能够看出哪些报社随时间的延续性较强，历史底蕴较为深厚，或是哪些报社在短期内有爆发式的发文趋势
 
 
## 事件发生期间的关键节点时间轴：基于TimelineJS的应用
### 数据来源
1. 通过分析经过筛选得到的会议期间的「关键文章」，并且按照时间排序、分别归纳后得到的一系列关键信息的整合`NewsCombined.txt`

### 数据预处理
1. 编写python脚本将`NewsCombined.txt`处理为TimelineJS基础样式所能够识别的序列化的json格式（见`djcode/mysite/static/timeline_js/data.json`）


### 数据可视化
 - 利用TimelineJS的Github项目主页上提供的嵌入代码和样式表文件，在服务器上架设了一个简单的时间线应用
 - 支持在下方时间轴上拖动、点击查看任意时间点的关键节点事件，也支持在上方的主显示区域左右按动，按顺序浏览
 
## 关键词汇和「关键文章」筛选：词云和可视化搜索引擎
### 数据来源
1. articles文件夹中所有的845篇报道，包含时间、报社信息（绝大多数）和正文内容

### 数据预处理
 - 利用Vector Space Model对比每两篇文章的相似度，具体为：
 	- 以两篇文章中出现过的词的并集作为用于比较的向量的维度，统计它们的词频，并计算两个向量经过归一化处理得到的内积
 	- 若内积的平方超过0.7的阈值，那么视时间较晚的一篇为有抄袭嫌疑的重复信息；若时间为同一天，那么认为较短的为重复信息
 	- 被判断有抄袭嫌疑的文章号被标记为待删除，为了加快筛选效率接下来不对这个待删除列表中的文章作对比而直接跳过
 	- 全部对比结束后，一次性删除全部被标记为抄袭嫌疑的文章（超过300篇）
 - 创建一个stopwords（意义不大的常见词汇）表
 - 对去重后的articles中各篇文章进行解析、分词后为除去stopwords中的词以外的所有词汇分别建立倒排索引，每个索引文件每行的格式为`出现该词的文章序号:出现次数：出现行数1:出现行数2:...:最后一个出现行数`
 
### 数据可视化
 - 编写脚本将全部文章和2014年的文章分别整理、精简到Summing.txt和Summing2014.txt中并利用在线词云生成器获得可视化结果，从中可获取全局和事件发生时间段分别的高频词汇，以备作进一步的分析
 - 架设了一个搜索引擎的前端
 	- 基础版本为文字显示搜索结果，支持多关键字交集搜索；对于每一个关键字找到索引，计算出现过的文章与其对应的TF-IDF值，并以之为根据作相关度排序，对于每项结果显示文章相关段落的快照，方便初步了解事件内容、提取关键信息
 	- 可视化版本为词云显示搜索结果，将搜索出含该关键字的文章整理出来，按stopwords表精简、合并后存放为一个服务器端静态文件地址下的临时文件，并将搜索结果页面转链到一个在线词云生成器，将临时文件地址作为参数交给它，以获得效果较好的搜索结果对应的词云
 	
##脚本及数据文件解释

|         文件名        |                                  用途                                       |
|-----------------------|-----------------------------------------------------------------------------|
| pre.py           | 包含统计出paperStat.txt、articleTime.csv的两个功能模块                                                     |
| paperStat.txt          | 各报社发文总数的统计                                                    |
| articleTime.csv          | 每篇报道的[编号，时间，报社名]，用于减小许多后续处理脚本的工作量 |
| indexer.py  | 读取articles/建各term的倒排索引的脚本                                                          |
| tsvGenerator.py      | 生成区域式折线图和堆栈式区域图所需的数据文件的脚本                                                            |
| data.json            | 区域式折线图所需的数据文件                                                          |
| muchdata.json          | 堆栈式区域图所需的数据文件                                               |
| divideByDay.py           | 将报道文章按日期分开的脚本                                                        |
| divideByYear.py            | 将报道文章按年份分开的脚本                                                          |
| divideByYear-pok.py          | 将含“pok”的报道文章按年份分开的脚本                                               |
| who_copies_who.py           | 统计报社之间互相抄袭关系系数，并生成抄袭关系和报社观点集群关系力学图所需的数据文件的脚本                                                      |
| copied_times.txt          | who_copies_who.py 预览输出并排序的结果                                               |
| copy.json           | 抄袭关系和报社观点集群关系力学图所需的数据文件                                                      |


##感想

