## 报道数量与时间和主要报社关系分析：区域式折线图和堆栈式区域图
### 数据来源
1. articles文件夹中所有的845篇报道，包含时间、报社信息（绝大多数）和正文内容

### 数据预处理
1. 编写python脚本分析所有的报道文本，识别出对应的发文时间和报社信息并转化为统一的格式，存入中间文件`articleTime.csv`以备后续数据预处理过程方便使用
2. 编写python脚本从中间文件中读取数据，将报道按日期切分复制到`ByDay/`中的各个子文件夹，并分别统计各个有报道文章出现的日期的文章数量，以`tsv day-month-year	number`格式存储
3. 编写python脚本从中间文件中读取数据，将报道按年份切分复制到`ByYear/`中的各个子文件夹，并分别统计各年度几个主要报社的文章在它们的文章总数中所占比例，以`year	The-Abila-Post	News-Online-Today	Kronos-Star	Homeland-Illumination	Centrum-Sentinel`格式存储，其中每项数字都是以0-100的浮点数表示的比例值。

### 数据可视化
 - 一个表示总的报道数量随时间推延的变化趋势的区域式折线图，横轴表示日期，纵轴蓝色部分高度表示当日的文章数量；能够清晰地分辨出文章高度集中在14年往后的情况，因此对近期文章进行基于时间序列关系的分析并非十分有效
 - 一个表示几个主要报社（发文总数量占优的五家）每年度报道数量占它们总和比例的堆栈式区域图，每种颜色代表一个报社，同种颜色在同一横轴座标上对应的纵轴高度表示相对的报道数量比例；能够看出哪些报社随时间的延续性较强，历史底蕴较为深厚，或是哪些报社在短期内有爆发式的发文趋势
 
 
## 事件发生期间的关键节点时间轴：基于TimelineJS的应用
### 数据来源
1. 通过分析经过筛选得到的会议期间的「关键文章」，并且按照时间排序、分别归纳后得到的一系列关键信息的整合`NewsCombined.txt`

### 数据预处理
1. 编写python脚本将`NewsCombined.txt`处理为TimelineJS基础样式所能够识别的序列化的json格式（见`djcode/mysite/static/timeline_js/data.json`）


### 数据可视化
 - 利用TimelineJS的Github项目主页上提供的嵌入代码和样式表文件，在服务器上架设了一个简单的时间线应用
 - 支持在下方时间轴上拖动、点击查看任意时间点的关键节点事件，也支持在上方的主显示区域左右按动，按顺序浏览
 
## 关键词汇和「关键文章」筛选：词云和可视化搜索引擎
### 数据来源
1. articles文件夹中所有的845篇报道，包含时间、报社信息（绝大多数）和正文内容

### 数据预处理
